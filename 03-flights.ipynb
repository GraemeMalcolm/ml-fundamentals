{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting flight arrivals\r\n",
    "\r\n",
    "## A simple binary classification example\r\n",
    "\r\n",
    "In this notebook, we'll explore *binary classification* - a form of machine learning in which we train a model to predict which to two categories, or *classes* something belongs. Specifically, we'll use details of flight records from the US department of transportation to train a model that predicts whether a flight will arrive late or on-time.\r\n",
    "\r\n",
    "Let's start by loading and viewing the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "df_flights = pd.read_csv('data/flights.csv')\r\n",
    "df_flights.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains observations of US domestic flights in 2013, and consists of the following fields:\r\n",
    "\r\n",
    "- **Year**: The year of the flight (all records are from 2013)\r\n",
    "- **Month**: The month of the flight\r\n",
    "- **DayofMonth**: The day of the month on which the flight departed\r\n",
    "- **DayOfWeek**: The day of the week on which the flight departed - from 1 (Monday) to 7 (Sunday)\r\n",
    "- **Carrier**: The two-letter abbreviation for the airline.\r\n",
    "- **OriginAirportID**: A unique numeric identifier for the departure aiport\r\n",
    "- **OriginAirportName**: The full name of the departure airport\r\n",
    "- **OriginCity**: The departure airport city\r\n",
    "- **OriginState**: The departure airport state\r\n",
    "- **DestAirportID**: A unique numeric identifier for the destination aiport\r\n",
    "- **DestAirportName**: The full name of the destination airport\r\n",
    "- **DestCity**: The destination airport city\r\n",
    "- **DestState**: The destination airport state\r\n",
    "- **CRSDepTime**: The scheduled departure time\r\n",
    "- **DepDelay**: The number of minutes departure was delayed (flight that left ahead of schedule have a negative value)\r\n",
    "- **ArrDelay15**: A binary indicator that departure was delayed by more than 15 minutes (and therefore considered \"late\")\r\n",
    "- **CRSArrTime**: The scheduled arrival time\r\n",
    "- **ArrDelay15**: A binary indicator that arrival was delayed by more than 15 minutes (and therefore considered \"late\")\r\n",
    "- **Cancelled**: A binary indicator that the flight was cancelled"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean the data\r\n",
    "\r\n",
    "Before we can train a model, we need to clean and explore the data. First. let's see if there are any missing values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_flights.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like there are some null \"late departure\" indicators. Departures are considered late if the delay is 15 minutes or more, so let's see the delays for the ones with a null late indicator:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_flights[df_flights.isnull().any(axis=1)][['DepDelay','DepDel15']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can't see them all in this display, but it looks like they may all have delay of 0. Let's check by looking at the summary statistics for these records:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_flights[df_flights.isnull().any(axis=1)].DepDelay.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The min, max, and mean are all 0; so it seems that none of these were actually *late* departures. Let's replace the missing **DepDel15** indicator with a 0 and confirm there are no more missing values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_flights.DepDel15 = df_flights.DepDel15.fillna(0)\r\n",
    "df_flights.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the dataset contains many numeric values, most of these represent *categorical* variables (for example, months, days, airports, ...). The only actual numeric value that represents a quantity we can measure is the departure delay.\r\n",
    "\r\n",
    "Let's take a look at the distribution and summary statistics for the *DepDelay* column to get a sense of typical departure delays.\r\n",
    "\r\n",
    "> **Note**: We'll want to do this again, so we'll define a function that we can use with any column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to show summary stats and distribution for a column\r\n",
    "def show_distribution(var_data):\r\n",
    "    from matplotlib import pyplot as plt\r\n",
    "    %matplotlib inline\r\n",
    "\r\n",
    "    # Get statistics\r\n",
    "    min_val = var_data.min()\r\n",
    "    max_val = var_data.max()\r\n",
    "    mean_val = var_data.mean()\r\n",
    "    med_val = var_data.median()\r\n",
    "    mod_val = var_data.mode()[0]\r\n",
    "\r\n",
    "    print(var_data.name,'\\nMinimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\r\n",
    "                                                                                            mean_val,\r\n",
    "                                                                                            med_val,\r\n",
    "                                                                                            mod_val,\r\n",
    "                                                                                            max_val))\r\n",
    "\r\n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)\r\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\r\n",
    "\r\n",
    "    # Plot the histogram   \r\n",
    "    ax[0].hist(var_data)\r\n",
    "    ax[0].set_ylabel('Frequency')\r\n",
    "\r\n",
    "    # Add lines for the mean, median, and mode\r\n",
    "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\r\n",
    "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\r\n",
    "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\r\n",
    "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\r\n",
    "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\r\n",
    "\r\n",
    "    # Plot the boxplot   \r\n",
    "    ax[1].boxplot(var_data, vert=False)\r\n",
    "    ax[1].set_xlabel('Value')\r\n",
    "\r\n",
    "    # Add a title to the Figure\r\n",
    "    fig.suptitle(var_data.name)\r\n",
    "\r\n",
    "    # Show the figure\r\n",
    "    fig.show()\r\n",
    "\r\n",
    "# Call the function for the DepDelay field\r\n",
    "show_distribution(df_flights['DepDelay'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The departure delays are measured in minutes, with negative values indicating early departures. The distribution of the data is extremely *left-skewed*; in other words, the bulk of the data is at the lower end. The *mean* value is quite low, which is what you might expect (most flights depart on time, with some slight delays and some slightly early departures). However, there are a few extremely high values that have the effect of increasing the *mean* delay. On the boxplot, you can clearly see a lot of **o** markers that indicate statistical *outliers* - values that are abnormally outside of the distribution of most of the data - in this case, values that are unusally high.\r\n",
    "\r\n",
    "Often, outliers represent atypical cases that might bias a model. Let's trim the data so that we include only rows where the departure delay is within the 1st and 90th percentile."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Trim outliers for DepDelay based on 1% and 90% percentiles\r\n",
    "DepDelay_01pcntile = df_flights.DepDelay.quantile(0.01)\r\n",
    "DepDelay_90pcntile = df_flights.DepDelay.quantile(0.90)\r\n",
    "df_flights = df_flights[df_flights.DepDelay < DepDelay_90pcntile]\r\n",
    "df_flights = df_flights[df_flights.DepDelay > DepDelay_01pcntile]\r\n",
    "\r\n",
    "# View the revised distributions\r\n",
    "show_distribution(df_flights['DepDelay'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "OK, so now we have a representative set of flights based on departure delays, let's compare how many arrived late and how many arrived on time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "    \r\n",
    "label_counts = df_flights['ArrDel15'].value_counts()\r\n",
    "fig = plt.figure(figsize=(6,6)) \r\n",
    "ax = fig.gca() \r\n",
    "label_counts.plot.bar(ax=ax) \r\n",
    "ax.set_title('Late Arrival Counts') \r\n",
    "ax.set_xlabel('Late?') \r\n",
    "ax.set_ylabel('Flights')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains many more examples of flights that were on time than flights that were late. In other words, the dataset is *imbalanced*. While for travellers, this is good news (many more flight arrive on time than are late), from the perspective of training a machine learning model it may bias the model. It's generally better to train a classification model with a more or less even number of cases for each class.\r\n",
    "\r\n",
    "There are two main approaches we could use to balance the data:\r\n",
    "\r\n",
    "- *Undersample* the majority case - in other words, eliminate some of the \"on-time\" cases to match the number of \"late\" cases. This is a legitimate strategy if it will leave enough cases with which to train a model effectively.\r\n",
    "- *Oversample* the minority case - in other words create more \"late\" cases to match the number of \"on-time\" cases. We could do this simply by duplicating \"late\" cases; essentially double (or triple) counting them, or by generating new cases that are statistically similar to existing \"late\" cases (commonly referred to as Synthetic Minority Oversampling Technique, or SMOTE).\r\n",
    "\r\n",
    "In this case, the are over 25,000 late cases; so if we undersample on-time cases to randomly select the same number of late cases,that gives us a balanced dataset with over 50,000 cases; which should be enough to train a model with. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the late cases\r\n",
    "df_late = df_flights[df_flights['ArrDel15'] != 0]\r\n",
    "\r\n",
    "# get a sample of the same number of on-time cases\r\n",
    "df_ontime = df_flights[df_flights['ArrDel15'] == 0].sample(len(df_late))\r\n",
    "\r\n",
    "# Combine them to create a balanced sample\r\n",
    "df_balanced = df_late.append(df_ontime)\r\n",
    "\r\n",
    "# Plot the counts of each class\r\n",
    "label_counts = df_balanced['ArrDel15'].value_counts()\r\n",
    "fig = plt.figure(figsize=(6,6)) \r\n",
    "ax = fig.gca() \r\n",
    "label_counts.plot.bar(ax=ax) \r\n",
    "ax.set_title('Late Arrival Counts') \r\n",
    "ax.set_xlabel('Late?') \r\n",
    "ax.set_ylabel('Flights')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "OK, so now we have a balanced dataset, let's explore the data and see if we can determine some relationships.\r\n",
    "\r\n",
    "We know that the dataset contains one numeric feature (*DepDelay*), so a good starting point might be to compare the distribution of departure delays for flights that arrived on time against flights that arrived late."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(6,6)) \r\n",
    "ax = fig.gca()\r\n",
    "df_balanced.boxplot(column='DepDelay', by='ArrDel15', ax=ax)\r\n",
    "ax.set_title('Departure Delay Distributions')\r\n",
    "ax.set_ylabel(\"Flights\")\r\n",
    "ax.set_xlabel(\"Late?\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unsurprisingly, the median departure delay for flights that arrived late is higher than that of on-time arrivals - indicating that there may be a relationship between late departures and late arrivals. In other words, the length of departure delay may be a good indicator of whether or not the flight will arrive on time.\r\n",
    "\r\n",
    "Now let's look at some of the *categorical* features in our dataset, and see if we can determine any relationships between them and whether or not flights arrive late or on-time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'Carrier', 'OriginAirportID', 'DestAirportID', 'OriginCity', 'DestCity', 'OriginState', 'DestState']\r\n",
    "\r\n",
    "for col in features:\r\n",
    "\r\n",
    "# Group by feature\r\n",
    "    group = df_balanced.groupby(df_balanced[col])\r\n",
    "    df_grouped = pd.DataFrame(group['ArrDel15'].sum()).sort_values(col)\r\n",
    "\r\n",
    "    # Plot the counts of each class\r\n",
    "    fig = plt.figure(figsize=(16,6)) \r\n",
    "    ax = fig.gca() \r\n",
    "    df_grouped.plot.bar(ax=ax) \r\n",
    "    ax.set_title('Late Arrivals by {}'.format(col)) \r\n",
    "    ax.set_xlabel(col) \r\n",
    "    ax.set_ylabel('Late Arrivals')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset only includes one year, so that's not particularly useful. Some of the other columns however do show some variability in the number of late arrivals, so they may help predict whether or not a flight will be late or on-time.\r\n",
    "\r\n",
    "There are too many airport codes to make much sense of the bar charts for those, and thinking about it logically, a more realistic way to determine the relationship between airports and late arrivals might be to consider each combination of otigin and destination airports - in other words *routes*. Let's explore that intuition that by grouping the origin and destination route combinations and counting the number of late arrivals for each. There's an enormous number of combinations, so we'll just look at a sample of 100 of them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a routes table\r\n",
    "routes  = pd.Series(df_balanced['OriginAirportName'] + ' > ' + df_balanced['DestAirportName'])\r\n",
    "df_routes = pd.concat([df_balanced, routes.rename(\"Route\")], axis=1)\r\n",
    "\r\n",
    "# Group by routes\r\n",
    "route_group = df_routes.groupby(df_routes['Route'])\r\n",
    "df_grouped =  pd.DataFrame(route_group['ArrDel15'].sum()).sample(100).sort_values('Route')\r\n",
    "\r\n",
    "# Plot the counts of each class\r\n",
    "fig = plt.figure(figsize=(16,6)) \r\n",
    "ax = fig.gca() \r\n",
    "df_grouped.plot.bar(ax=ax) \r\n",
    "ax.set_title('Late Arrivals by Route') \r\n",
    "ax.set_xlabel('Route') \r\n",
    "ax.set_ylabel('Late Arrivals')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results show that some routes have a high number of late arrivals, while others have none - so  the route might help predict whether a flight will be late or on-time. \r\n",
    "\r\n",
    "So far, we haven't considered the scheduled departure and arrival times (*CRSDepTime* and *CRSArrTime*). These values are integer numbers that represent the time in 24-hour clock notation (so for example, 710 represents 7:10am, and 2108 represents 9:08pm). Comparing times for every minute may result in two many categories, but what if we compare delays for each hour of the day (0 to 23)?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_cols = ['CRSDepTime', 'CRSArrTime']\r\n",
    "for col in time_cols:\r\n",
    "\r\n",
    "# Group by feature\r\n",
    "    group = df_balanced.groupby(round(df_balanced[col]/100, 0))\r\n",
    "    df_grouped = pd.DataFrame(group['ArrDel15'].sum()).sort_values(col)\r\n",
    "\r\n",
    "    # Plot the counts of each class\r\n",
    "    fig = plt.figure(figsize=(16,6)) \r\n",
    "    ax = fig.gca() \r\n",
    "    df_grouped.plot.bar(ax=ax) \r\n",
    "    ax.set_title('Late Arrivals by {}'.format(col)) \r\n",
    "    ax.set_xlabel(col) \r\n",
    "    ax.set_ylabel('Late Arrivals')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like there's a pattern for both scheduled departure and arrival times. In which flights scheduled to depart or arrive in the late afternoon or evening (between 2:00pm and 8:00pm) tend to have the more late arrivals than flights scheduled in the early hours of the morning.\r\n",
    "\r\n",
    "All of this exploratory data analysis provides us with some ideas of which features are likely to help predict whether a flight will be late or on-time. Let's add columns for the derived features we've identified as potentially useful (route, scheduled departure hour, and scheduled arrival hour) to the dataset (this kind of creation of new features is often referred to as *feature engineering*), and then select the subset of features we want to use to train a classification model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a copy of the balanced dataframe\r\n",
    "df_flight_data = df_balanced.copy()\r\n",
    "\r\n",
    "# Add the scheduled hour columns\r\n",
    "for col in time_cols:\r\n",
    "    new_col = pd.Series(round(df_flight_data[col]/100, 0))\r\n",
    "    df_flight_data = pd.concat([df_flight_data, new_col.rename(col + '_Hour')], axis=1)\r\n",
    "\r\n",
    "# Add the route column\r\n",
    "df_flight_data = pd.concat([df_flight_data, routes.rename(\"Route\")], axis=1)\r\n",
    "\r\n",
    "# specify the features we want to use, and the label we want to predict\r\n",
    "features_and_label = ['DepDelay', 'Month', 'DayofMonth', 'DayOfWeek', 'Carrier', 'Route', 'CRSDepTime_Hour', 'CRSArrTime_Hour', 'ArrDel15']\r\n",
    "\r\n",
    "df_flight_data = df_flight_data[features_and_label]\r\n",
    "df_flight_data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the model\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "# Separate features and labels\r\n",
    "features = ['DepDelay', 'Month', 'DayofMonth', 'DayOfWeek', 'Carrier', 'Route', 'CRSDepTime_Hour', 'CRSArrTime_Hour']\r\n",
    "label = 'ArrDel15'\r\n",
    "X, y = df_flight_data[features].values, df_flight_data[label].values\r\n",
    "\r\n",
    "# Split data 70%-30% into training set and test set\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
    "\r\n",
    "# Normalize the numeric columns\r\n",
    "numeric_features = [0]\r\n",
    "numeric_transformer = Pipeline(steps=[\r\n",
    "    ('scaler', StandardScaler())])\r\n",
    "\r\n",
    "# Encode the categorical features\r\n",
    "categorical_features = [1,2,3,4,5,6,7]\r\n",
    "categorical_transformer = Pipeline(steps=[\r\n",
    "    ('ordinal_encode', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\r\n",
    "\r\n",
    "# Combine preprocessing steps\r\n",
    "preprocessor = ColumnTransformer(\r\n",
    "    transformers=[\r\n",
    "        ('num', numeric_transformer, numeric_features),\r\n",
    "        ('cat', categorical_transformer, categorical_features)]\r\n",
    "    )\r\n",
    "\r\n",
    "# Create preprocessing and training pipeline\r\n",
    "reg = 0.01\r\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
    "                           ('classifier', LogisticRegression(C=1/reg, solver=\"liblinear\"))])\r\n",
    "\r\n",
    "\r\n",
    "# fit the pipeline to train a model on the training set, including the pre-processing steps\r\n",
    "model = pipeline.fit(X_train, y_train)\r\n",
    "print (model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions = model.predict(X_test)\r\n",
    "print('Predicted labels: ', predictions)\r\n",
    "print('Actual labels:    ' ,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn. metrics import classification_report\r\n",
    "\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import precision_score, recall_score\r\n",
    "\r\n",
    "print(\"Overall Precision:\",precision_score(y_test, predictions))\r\n",
    "print(\"Overall Recall:\",recall_score(y_test, predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "# Print the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "print (cm)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "classes = ['on-time', 'late']\r\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\r\n",
    "plt.colorbar()\r\n",
    "tick_marks = np.arange(len(classes))\r\n",
    "plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "plt.yticks(tick_marks, classes)\r\n",
    "plt.xlabel(\"Predicted Class\")\r\n",
    "plt.ylabel(\"Actual Class\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_scores = model.predict_proba(X_test)\r\n",
    "print(y_scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_curve\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# calculate ROC curve\r\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\r\n",
    "\r\n",
    "# plot ROC curve\r\n",
    "fig = plt.figure(figsize=(6, 6))\r\n",
    "# Plot the diagonal 50% line\r\n",
    "plt.plot([0, 1], [0, 1], 'k--')\r\n",
    "# Plot the FPR and TPR achieved by our model\r\n",
    "plt.plot(fpr, tpr)\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
    "print('AUC: ' + str(auc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "\r\n",
    "# Create preprocessing and training pipeline\r\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
    "                           ('classifier', GradientBoostingClassifier())])\r\n",
    "\r\n",
    "# fit the pipeline to train a model on the training set\r\n",
    "model = pipeline.fit(X_train, (y_train))\r\n",
    "\r\n",
    "# Evaluate model\r\n",
    "predictions = model.predict(X_test)\r\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# Plot confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\r\n",
    "plt.colorbar()\r\n",
    "tick_marks = np.arange(len(classes))\r\n",
    "plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "plt.yticks(tick_marks, classes)\r\n",
    "plt.xlabel(\"Predicted Class\")\r\n",
    "plt.ylabel(\"Actual Class\")\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# plot ROC curve\r\n",
    "y_scores = model.predict_proba(X_test)\r\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\r\n",
    "fig = plt.figure(figsize=(6, 6))\r\n",
    "plt.plot([0, 1], [0, 1], 'k--')\r\n",
    "plt.plot(fpr, tpr)\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "plt.show()\r\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
    "print('AUC: ' + str(auc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "\r\n",
    "# Create preprocessing and training pipeline\r\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
    "                           ('classifier', GradientBoostingClassifier(learning_rate=0.5, n_estimators=100))])\r\n",
    "\r\n",
    "# fit the pipeline to train a model on the training set\r\n",
    "model = pipeline.fit(X_train, (y_train))\r\n",
    "\r\n",
    "# Evaluate model\r\n",
    "predictions = model.predict(X_test)\r\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\r\n",
    "print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# Plot confusion matrix\r\n",
    "cm = confusion_matrix(y_test, predictions)\r\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\r\n",
    "plt.colorbar()\r\n",
    "tick_marks = np.arange(len(classes))\r\n",
    "plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "plt.yticks(tick_marks, classes)\r\n",
    "plt.xlabel(\"Predicted Class\")\r\n",
    "plt.ylabel(\"Actual Class\")\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# plot ROC curve\r\n",
    "y_scores = model.predict_proba(X_test)\r\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\r\n",
    "fig = plt.figure(figsize=(6, 6))\r\n",
    "plt.plot([0, 1], [0, 1], 'k--')\r\n",
    "plt.plot(fpr, tpr)\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "plt.show()\r\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
    "print('AUC: ' + str(auc))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "d631c4f8937aff5a00d938bb761b79b71fe773d07f3a79c191fcf956b8a61c95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}